// Code generated by command: go run generate.go -out ../simd_fma_amd64.s. DO NOT EDIT.

#include "textflag.h"

// func dot32FMA(a uintptr, b uintptr) float32
// Requires: AVX, AVX512DQ, AVX512F, SSE
TEXT ·dot32FMA(SB), NOSPLIT, $0-20
	MOVQ          a+0(FP), AX
	MOVQ          b+8(FP), CX
	VXORPS        Z2, Z2, Z2
	VMOVUPS       (AX), Z0
	VMOVUPS       (CX), Z1
	VFMADD231PS   Z0, Z1, Z2
	VMOVUPS       64(AX), Z0
	VMOVUPS       64(CX), Z1
	VFMADD231PS   Z0, Z1, Z2
	VEXTRACTF32X8 $0x01, Z2, Y0
	VADDPS        Y0, Y2, Y0
	VEXTRACTF128  $0x01, Y0, X1
	VADDPS        X1, X0, X1
	VMOVHLPS      X1, X1, X0
	VADDPS        X0, X1, X1
	VMOVSHDUP     X1, X0
	VADDSS        X0, X1, X2
	MOVSS         X2, ret+16(FP)
	VZEROUPPER
	RET

// func dot64FMA(a uintptr, b uintptr) float32
// Requires: AVX, AVX512DQ, AVX512F, SSE
TEXT ·dot64FMA(SB), NOSPLIT, $0-20
	MOVQ          a+0(FP), AX
	MOVQ          b+8(FP), CX
	VXORPS        Z0, Z0, Z0
	VXORPS        Z1, Z1, Z1
	VXORPS        Z2, Z2, Z2
	VXORPS        Z3, Z3, Z3
	VMOVUPS       (AX), Z4
	VMOVUPS       (CX), Z5
	VFMADD231PS   Z4, Z5, Z0
	VMOVUPS       64(AX), Z4
	VMOVUPS       64(CX), Z5
	VFMADD231PS   Z4, Z5, Z1
	VMOVUPS       128(AX), Z4
	VMOVUPS       128(CX), Z5
	VFMADD231PS   Z4, Z5, Z2
	VMOVUPS       192(AX), Z4
	VMOVUPS       192(CX), Z5
	VFMADD231PS   Z4, Z5, Z3
	VADDPS        Z1, Z0, Z0
	VADDPS        Z3, Z2, Z2
	VADDPS        Z2, Z0, Z0
	VEXTRACTF32X8 $0x01, Z0, Y1
	VADDPS        Y1, Y0, Y1
	VEXTRACTF128  $0x01, Y1, X0
	VADDPS        X0, X1, X0
	VMOVHLPS      X0, X0, X1
	VADDPS        X1, X0, X0
	VMOVSHDUP     X0, X1
	VADDSS        X1, X0, X0
	MOVSS         X0, ret+16(FP)
	VZEROUPPER
	RET

// func euclidean32FMA(a uintptr, b uintptr) float32
// Requires: AVX, AVX512DQ, AVX512F, SSE
TEXT ·euclidean32FMA(SB), NOSPLIT, $0-20
	MOVQ          a+0(FP), AX
	MOVQ          b+8(FP), CX
	VXORPS        Z0, Z0, Z0
	VMOVUPS       (AX), Z1
	VMOVUPS       (CX), Z2
	VSUBPS        Z2, Z1, Z1
	VFMADD231PS   Z1, Z1, Z0
	VMOVUPS       64(AX), Z1
	VMOVUPS       64(CX), Z2
	VSUBPS        Z2, Z1, Z1
	VFMADD231PS   Z1, Z1, Z0
	VEXTRACTF32X8 $0x01, Z0, Y1
	VADDPS        Y1, Y0, Y1
	VEXTRACTF128  $0x01, Y1, X0
	VADDPS        X0, X1, X0
	VMOVHLPS      X0, X0, X1
	VADDPS        X1, X0, X0
	VMOVSHDUP     X0, X1
	VADDSS        X1, X0, X0
	MOVSS         X0, ret+16(FP)
	VZEROUPPER
	RET

// func euclidean64FMA(a uintptr, b uintptr) float32
// Requires: AVX, AVX512DQ, AVX512F, SSE
TEXT ·euclidean64FMA(SB), NOSPLIT, $0-20
	MOVQ          a+0(FP), AX
	MOVQ          b+8(FP), CX
	VXORPS        Z0, Z0, Z0
	VXORPS        Z1, Z1, Z1
	VMOVUPS       (AX), Z2
	VMOVUPS       (CX), Z3
	VSUBPS        Z3, Z2, Z2
	VFMADD231PS   Z2, Z2, Z0
	VMOVUPS       64(AX), Z2
	VMOVUPS       64(CX), Z3
	VSUBPS        Z3, Z2, Z2
	VFMADD231PS   Z2, Z2, Z1
	VMOVUPS       128(AX), Z2
	VMOVUPS       128(CX), Z3
	VSUBPS        Z3, Z2, Z2
	VFMADD231PS   Z2, Z2, Z0
	VMOVUPS       192(AX), Z2
	VMOVUPS       192(CX), Z3
	VSUBPS        Z3, Z2, Z2
	VFMADD231PS   Z2, Z2, Z1
	VADDPS        Z1, Z0, Z0
	VEXTRACTF32X8 $0x01, Z0, Y1
	VADDPS        Y1, Y0, Y1
	VEXTRACTF128  $0x01, Y1, X0
	VADDPS        X0, X1, X0
	VMOVHLPS      X0, X0, X1
	VADDPS        X1, X0, X0
	VMOVSHDUP     X0, X1
	VADDSS        X1, X0, X0
	MOVSS         X0, ret+16(FP)
	VZEROUPPER
	RET

// func cosine32FMA(a uintptr, b uintptr) (dot float32, normA float32, normB float32)
// Requires: AVX, AVX512DQ, AVX512F, SSE
TEXT ·cosine32FMA(SB), NOSPLIT, $0-28
	MOVQ          a+0(FP), AX
	MOVQ          b+8(FP), CX
	VXORPS        Z0, Z0, Z0
	VXORPS        Z1, Z1, Z1
	VXORPS        Z2, Z2, Z2
	VMOVUPS       (AX), Z3
	VMOVUPS       (CX), Z4
	VFMADD231PS   Z3, Z4, Z0
	VFMADD231PS   Z3, Z3, Z1
	VFMADD231PS   Z4, Z4, Z2
	VMOVUPS       64(AX), Z3
	VMOVUPS       64(CX), Z4
	VFMADD231PS   Z3, Z4, Z0
	VFMADD231PS   Z3, Z3, Z1
	VFMADD231PS   Z4, Z4, Z2
	VEXTRACTF32X8 $0x01, Z0, Y3
	VADDPS        Y3, Y0, Y3
	VEXTRACTF128  $0x01, Y3, X0
	VADDPS        X0, X3, X0
	VMOVHLPS      X0, X0, X3
	VADDPS        X3, X0, X0
	VMOVSHDUP     X0, X3
	VADDSS        X3, X0, X0
	VEXTRACTF32X8 $0x01, Z1, Y3
	VADDPS        Y3, Y1, Y3
	VEXTRACTF128  $0x01, Y3, X1
	VADDPS        X1, X3, X1
	VMOVHLPS      X1, X1, X3
	VADDPS        X3, X1, X1
	VMOVSHDUP     X1, X3
	VADDSS        X3, X1, X1
	VEXTRACTF32X8 $0x01, Z2, Y3
	VADDPS        Y3, Y2, Y3
	VEXTRACTF128  $0x01, Y3, X2
	VADDPS        X2, X3, X2
	VMOVHLPS      X2, X2, X3
	VADDPS        X3, X2, X2
	VMOVSHDUP     X2, X3
	VADDSS        X3, X2, X2
	MOVSS         X0, dot+16(FP)
	MOVSS         X1, normA+20(FP)
	MOVSS         X2, normB+24(FP)
	VZEROUPPER
	RET
